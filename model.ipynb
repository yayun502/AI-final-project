{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify emotions in text with BERT NLP model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-06-10T14:32:32.581602Z",
     "iopub.status.busy": "2022-06-10T14:32:32.581246Z",
     "iopub.status.idle": "2022-06-10T14:32:32.591279Z",
     "shell.execute_reply": "2022-06-10T14:32:32.590169Z",
     "shell.execute_reply.started": "2022-06-10T14:32:32.581570Z"
    }
   },
   "outputs": [],
   "source": [
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2022-06-10T14:32:34.592079Z",
     "iopub.status.busy": "2022-06-10T14:32:34.591624Z",
     "iopub.status.idle": "2022-06-10T14:32:41.956894Z",
     "shell.execute_reply": "2022-06-10T14:32:41.955819Z",
     "shell.execute_reply.started": "2022-06-10T14:32:34.592036Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-10T14:32:45.434415Z",
     "iopub.status.busy": "2022-06-10T14:32:45.434053Z",
     "iopub.status.idle": "2022-06-10T14:32:45.447397Z",
     "shell.execute_reply": "2022-06-10T14:32:45.446318Z",
     "shell.execute_reply.started": "2022-06-10T14:32:45.434367Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "import torch.nn.functional as F\n",
    "from transformers import BertTokenizer, BertConfig,AdamW, BertForSequenceClassification,get_linear_schedule_with_warmup\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "# Import and evaluate each test batch using Matthew's correlation coefficient\n",
    "from sklearn.metrics import accuracy_score,matthews_corrcoef\n",
    "\n",
    "from tqdm import tqdm, trange,tnrange,tqdm_notebook\n",
    "import random\n",
    "import os\n",
    "import io\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-10T14:32:48.711063Z",
     "iopub.status.busy": "2022-06-10T14:32:48.710722Z",
     "iopub.status.idle": "2022-06-10T14:32:48.800548Z",
     "shell.execute_reply": "2022-06-10T14:32:48.799373Z",
     "shell.execute_reply.started": "2022-06-10T14:32:48.711027Z"
    }
   },
   "outputs": [],
   "source": [
    "# identify and specify the GPU as the device, later in training loop we will load data into device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()\n",
    "torch.cuda.get_device_name(0)\n",
    "\n",
    "SEED = 19\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if device == torch.device(\"cuda\"):\n",
    "    torch.cuda.manual_seed_all(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-10T14:32:51.186051Z",
     "iopub.status.busy": "2022-06-10T14:32:51.185695Z",
     "iopub.status.idle": "2022-06-10T14:32:51.191204Z",
     "shell.execute_reply": "2022-06-10T14:32:51.190070Z",
     "shell.execute_reply.started": "2022-06-10T14:32:51.186015Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BertTokenizer to run end-to-end tokenization: punctuation splitting + word piece. \n",
    "BertForSequenceClassification is the Bert Model transformer with a sequence classification/regression head on top (a linear layer on top of the pooled output). \n",
    "BertConfig is the configuration class to store model configurations. \n",
    "AdamW implements Adam learning rate optimization algorithm, it is a type of Stochastic Gradient Descent with momentum. Here momentum is described as the moving average of the gradient instead of gradient itself.\n",
    "get_linear_schedule_with_warmup creates a schedule with a learning rate that decreases linearly after linearly increasing during a warm-up period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-10T14:32:53.524721Z",
     "iopub.status.busy": "2022-06-10T14:32:53.524405Z",
     "iopub.status.idle": "2022-06-10T14:32:53.624685Z",
     "shell.execute_reply": "2022-06-10T14:32:53.623687Z",
     "shell.execute_reply.started": "2022-06-10T14:32:53.524690Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"/kaggle/input/emotions-dataset-for-nlp/train.txt\", delimiter=';', header=None, names=['sentence','label'])\n",
    "df_test = pd.read_csv(\"/kaggle/input/emotions-dataset-for-nlp/test.txt\", delimiter=';', header=None, names=['sentence','label'])\n",
    "df_val = pd.read_csv(\"/kaggle/input/emotions-dataset-for-nlp/val.txt\", delimiter=';', header=None, names=['sentence','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-10T14:32:55.104355Z",
     "iopub.status.busy": "2022-06-10T14:32:55.104036Z",
     "iopub.status.idle": "2022-06-10T14:32:55.112145Z",
     "shell.execute_reply": "2022-06-10T14:32:55.111087Z",
     "shell.execute_reply.started": "2022-06-10T14:32:55.104317Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.concat([df_train,df_test,df_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-10T14:32:56.862893Z",
     "iopub.status.busy": "2022-06-10T14:32:56.862590Z",
     "iopub.status.idle": "2022-06-10T14:32:56.881156Z",
     "shell.execute_reply": "2022-06-10T14:32:56.880037Z",
     "shell.execute_reply.started": "2022-06-10T14:32:56.862862Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder = LabelEncoder()\n",
    "df['label_enc'] = labelencoder.fit_transform(df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-10T14:32:58.894934Z",
     "iopub.status.busy": "2022-06-10T14:32:58.894608Z",
     "iopub.status.idle": "2022-06-10T14:32:58.909790Z",
     "shell.execute_reply": "2022-06-10T14:32:58.908672Z",
     "shell.execute_reply.started": "2022-06-10T14:32:58.894881Z"
    }
   },
   "outputs": [],
   "source": [
    "df.rename(columns={'label':'label_desc'},inplace=True)\n",
    "df.rename(columns={'label_enc':'label'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-10T14:33:00.475594Z",
     "iopub.status.busy": "2022-06-10T14:33:00.475219Z",
     "iopub.status.idle": "2022-06-10T14:33:20.203277Z",
     "shell.execute_reply": "2022-06-10T14:33:20.202365Z",
     "shell.execute_reply.started": "2022-06-10T14:33:00.475552Z"
    }
   },
   "outputs": [],
   "source": [
    "## create label and sentence list\n",
    "sentences = df.sentence.values\n",
    "\n",
    "#check distribution of data based on labels\n",
    "\n",
    "# Set the maximum sequence length. The longest sequence in our training set is 47, but we'll leave room on the end anyway. \n",
    "MAX_LEN = 256\n",
    "from transformers import BertTokenizer, BertModel\n",
    "## Import BERT tokenizer, that is used to convert our text into tokens that corresponds to BERT library\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased',do_lower_case=True)\n",
    "input_ids = [tokenizer.encode(sent, add_special_tokens=True,max_length=MAX_LEN,pad_to_max_length=True) for sent in sentences]\n",
    "labels = df.label.values\n",
    "\n",
    "## Create attention mask\n",
    "attention_masks = []\n",
    "## Create a mask of 1 for all input tokens and 0 for all padding tokens\n",
    "attention_masks = [[float(i>0) for i in seq] for seq in input_ids]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Prep for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split into a training set and a test set using a stratified k fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-10T14:35:01.167748Z",
     "iopub.status.busy": "2022-06-10T14:35:01.167423Z",
     "iopub.status.idle": "2022-06-10T14:35:01.204112Z",
     "shell.execute_reply": "2022-06-10T14:35:01.203162Z",
     "shell.execute_reply.started": "2022-06-10T14:35:01.167715Z"
    }
   },
   "outputs": [],
   "source": [
    "train_inputs,validation_inputs,train_labels,validation_labels = train_test_split(input_ids,labels,random_state=41,test_size=0.1)\n",
    "train_masks,validation_masks,_,_ = train_test_split(attention_masks,input_ids,random_state=41,test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-10T14:35:03.164177Z",
     "iopub.status.busy": "2022-06-10T14:35:03.163846Z",
     "iopub.status.idle": "2022-06-10T14:35:03.839539Z",
     "shell.execute_reply": "2022-06-10T14:35:03.838443Z",
     "shell.execute_reply.started": "2022-06-10T14:35:03.164146Z"
    }
   },
   "outputs": [],
   "source": [
    "# convert all our data into torch tensors, required data type for our model\n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "train_labels = torch.tensor(train_labels)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "train_masks = torch.tensor(train_masks)\n",
    "validation_masks = torch.tensor(validation_masks)\n",
    "\n",
    "# Select a batch size for training.\n",
    "batch_size = 32\n",
    "\n",
    "# Create an iterator of our data with torch DataLoader. This helps save on memory during training because, unlike a for loop, \n",
    "# with an iterator the entire dataset does not need to be loaded into memory\n",
    "train_data = TensorDataset(train_inputs,train_masks,train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data,sampler=train_sampler,batch_size=batch_size)\n",
    "\n",
    "validation_data = TensorDataset(validation_inputs,validation_masks,validation_labels)\n",
    "validation_sampler = RandomSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data,sampler=validation_sampler,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-10T14:35:05.921656Z",
     "iopub.status.busy": "2022-06-10T14:35:05.921196Z",
     "iopub.status.idle": "2022-06-10T14:35:33.876899Z",
     "shell.execute_reply": "2022-06-10T14:35:33.875981Z",
     "shell.execute_reply.started": "2022-06-10T14:35:05.921609Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load BertForSequenceClassification, the pretrained BERT model with a single linear classification layer on top. \n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=6).to(device)\n",
    "\n",
    "lr = 2e-5\n",
    "adam_epsilon = 1e-8\n",
    "\n",
    "# Number of training epochs \n",
    "epochs = 3\n",
    "\n",
    "num_warmup_steps = 0\n",
    "num_training_steps = len(train_dataloader)*epochs\n",
    "\n",
    "### In Transformers, optimizer and schedules are splitted and instantiated like this:\n",
    "optimizer = AdamW(model.parameters(), lr=lr,eps=adam_epsilon,correct_bias=False)  # To reproduce BertAdam specific behavior set correct_bias=False\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=num_training_steps)  # PyTorch scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-10T14:40:18.940222Z",
     "iopub.status.busy": "2022-06-10T14:40:18.938707Z",
     "iopub.status.idle": "2022-06-10T15:02:57.284024Z",
     "shell.execute_reply": "2022-06-10T15:02:57.281433Z",
     "shell.execute_reply.started": "2022-06-10T14:40:18.940168Z"
    }
   },
   "outputs": [],
   "source": [
    "## Store our loss and accuracy for plotting\n",
    "train_loss_set = []\n",
    "learning_rate = []\n",
    "\n",
    "# Gradients gets accumulated by default\n",
    "model.zero_grad()\n",
    "\n",
    "# tnrange is a tqdm wrapper around the normal python range\n",
    "for _ in tnrange(1,epochs+1,desc='Epoch'):\n",
    "    print(\"<\" + \"=\"*22 + F\" Epoch {_} \"+ \"=\"*22 + \">\")\n",
    "    # Calculate total loss for this epoch\n",
    "    batch_loss = 0\n",
    "\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        # Set our model to training mode (as opposed to evaluation mode)\n",
    "        model.train()\n",
    "\n",
    "        # Add batch to GPU\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        # Unpack the inputs from our dataloader\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
    "        loss = outputs[0]\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0\n",
    "        # Gradient clipping is not in AdamW anymore\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Update parameters and take a step using the computed gradient\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update learning rate schedule\n",
    "        scheduler.step()\n",
    "\n",
    "        # Clear the previous accumulated gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Update tracking variables\n",
    "        batch_loss += loss.item()\n",
    "\n",
    "    # Calculate the average loss over the training data.\n",
    "    avg_train_loss = batch_loss / len(train_dataloader)\n",
    "\n",
    "    #store the current learning rate\n",
    "    for param_group in optimizer.param_groups:\n",
    "        print(\"\\n\\tCurrent Learning rate: \",param_group['lr'])\n",
    "        learning_rate.append(param_group['lr'])\n",
    "    \n",
    "    train_loss_set.append(avg_train_loss)\n",
    "    print(F'\\n\\tAverage Training loss: {avg_train_loss}')\n",
    "    \n",
    "    # Validation\n",
    "\n",
    "    # Put model in evaluation mode to evaluate loss on the validation set\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables \n",
    "    eval_accuracy,eval_mcc_accuracy,nb_eval_steps = 0, 0, 0\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        # Add batch to GPU\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        # Unpack the inputs from our dataloader\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        # Telling the model not to compute or store gradients, saving memory and speeding up validation\n",
    "        with torch.no_grad():\n",
    "          # Forward pass, calculate logit predictions\n",
    "          logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
    "\n",
    "        # Move logits and labels to CPU\n",
    "        logits = logits[0].to('cpu').numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        pred_flat = np.argmax(logits, axis=1).flatten()\n",
    "        labels_flat = label_ids.flatten()\n",
    "\n",
    "        df_metrics=pd.DataFrame({'Epoch':epochs,'Actual_class':labels_flat,'Predicted_class':pred_flat})\n",
    "\n",
    "        tmp_eval_accuracy = accuracy_score(labels_flat,pred_flat)\n",
    "        tmp_eval_mcc_accuracy = matthews_corrcoef(labels_flat, pred_flat)\n",
    "\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "        eval_mcc_accuracy += tmp_eval_mcc_accuracy\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "    print(F'\\n\\tValidation Accuracy: {eval_accuracy/nb_eval_steps}')\n",
    "    print(F'\\n\\tValidation MCC Accuracy: {eval_mcc_accuracy/nb_eval_steps}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-10T15:04:51.586624Z",
     "iopub.status.busy": "2022-06-10T15:04:51.586265Z",
     "iopub.status.idle": "2022-06-10T15:04:51.621812Z",
     "shell.execute_reply": "2022-06-10T15:04:51.620816Z",
     "shell.execute_reply.started": "2022-06-10T15:04:51.586589Z"
    }
   },
   "outputs": [],
   "source": [
    "df[['label','label_desc']].drop_duplicates(keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-10T15:04:53.686428Z",
     "iopub.status.busy": "2022-06-10T15:04:53.686087Z",
     "iopub.status.idle": "2022-06-10T15:04:53.692232Z",
     "shell.execute_reply": "2022-06-10T15:04:53.691133Z",
     "shell.execute_reply.started": "2022-06-10T15:04:53.686387Z"
    }
   },
   "outputs": [],
   "source": [
    "## emotion labels\n",
    "label2int = {\n",
    "  \"sadness\": 4,\n",
    "  \"joy\": 2,\n",
    "  \"love\": 3,\n",
    "  \"anger\": 0,\n",
    "  \"fear\": 1,\n",
    "  \"surprise\": 5\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the models for future use "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-10T15:20:07.137106Z",
     "iopub.status.busy": "2022-06-10T15:20:07.136772Z",
     "iopub.status.idle": "2022-06-10T15:20:11.728797Z",
     "shell.execute_reply": "2022-06-10T15:20:11.727237Z",
     "shell.execute_reply.started": "2022-06-10T15:20:07.137074Z"
    }
   },
   "outputs": [],
   "source": [
    "model_save_folder = 'model/'\n",
    "tokenizer_save_folder = 'tokenizer/'\n",
    "\n",
    "path_model = F'/kaggle/working/{model_save_folder}'\n",
    "path_tokenizer = F'/kaggle/working/{tokenizer_save_folder}'\n",
    "\n",
    "#create the dir\n",
    "\n",
    "!mkdir -p {path_model}\n",
    "!mkdir -p {path_tokenizer}\n",
    "\n",
    "## Now let's save our model and tokenizer to a directory\n",
    "model.save_pretrained(path_model)\n",
    "tokenizer.save_pretrained(path_tokenizer)\n",
    "\n",
    "model_save_name = 'fineTuneModel.pt'\n",
    "path = path_model = F'/kaggle/working/{model_save_folder}/{model_save_name}'\n",
    "torch.save(model.state_dict(),path);\n",
    "\n",
    "model_save_name = 'fineTuneModel.bin'\n",
    "path = path_model = F'/kaggle/working/{model_save_name}'\n",
    "torch.save(model.state_dict(),path);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-10T15:20:14.928573Z",
     "iopub.status.busy": "2022-06-10T15:20:14.928177Z",
     "iopub.status.idle": "2022-06-10T15:20:14.979248Z",
     "shell.execute_reply": "2022-06-10T15:20:14.978266Z",
     "shell.execute_reply.started": "2022-06-10T15:20:14.928538Z"
    }
   },
   "outputs": [],
   "source": [
    "token = BertTokenizer.from_pretrained(\"./tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-10T15:20:17.870056Z",
     "iopub.status.busy": "2022-06-10T15:20:17.869655Z",
     "iopub.status.idle": "2022-06-10T15:20:23.405331Z",
     "shell.execute_reply": "2022-06-10T15:20:23.404263Z",
     "shell.execute_reply.started": "2022-06-10T15:20:17.870023Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import BertModel\n",
    "r_model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=6)\n",
    "r_model.load_state_dict(torch.load(\"./fineTuneModel.bin\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the levels' boundage for each emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-10T15:20:26.890374Z",
     "iopub.status.busy": "2022-06-10T15:20:26.890066Z",
     "iopub.status.idle": "2022-06-10T15:20:26.903164Z",
     "shell.execute_reply": "2022-06-10T15:20:26.902023Z",
     "shell.execute_reply.started": "2022-06-10T15:20:26.890343Z"
    }
   },
   "outputs": [],
   "source": [
    "Emo = ['anger', 'fear', 'joy', 'love', 'sadness', 'surprise']\n",
    "\n",
    "def result(sentence):\n",
    "    emotion = []\n",
    "    value = [[],[],[],[],[],[]]\n",
    "    tendency = []\n",
    "    for f in sentence:\n",
    "        seq = f\n",
    "        attention = [float(i>0) for i in seq]\n",
    "        seq = torch.tensor([seq]).to(device)\n",
    "        attention = torch.tensor([attention]).to(device)\n",
    "        result = model(seq, attention)\n",
    "\n",
    "        Max = -9999999\n",
    "        ctr = 0\n",
    "        idx = 0\n",
    "        for i in result[0][0].cpu().detach().numpy():\n",
    "            if Max < i:\n",
    "                Max = i\n",
    "                idx = ctr\n",
    "            ctr += 1\n",
    "\n",
    "        value[idx].append(result[0][0].cpu().detach().numpy()[idx])\n",
    "        emotion.append(Emo[idx])\n",
    "    return value, emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-10T15:20:29.650416Z",
     "iopub.status.busy": "2022-06-10T15:20:29.650035Z",
     "iopub.status.idle": "2022-06-10T15:28:01.694975Z",
     "shell.execute_reply": "2022-06-10T15:28:01.693797Z",
     "shell.execute_reply.started": "2022-06-10T15:20:29.650384Z"
    }
   },
   "outputs": [],
   "source": [
    "train_value, train_emotion = result(train_inputs)\n",
    "val_value, val_emotion = result(validation_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-10T15:31:28.838397Z",
     "iopub.status.busy": "2022-06-10T15:31:28.838035Z",
     "iopub.status.idle": "2022-06-10T15:31:28.852481Z",
     "shell.execute_reply": "2022-06-10T15:31:28.851243Z",
     "shell.execute_reply.started": "2022-06-10T15:31:28.838364Z"
    }
   },
   "outputs": [],
   "source": [
    "def ComputeBoundary(train_value):\n",
    "    boundary = []\n",
    "    for i in train_value:\n",
    "        one = int(len(i)/3)\n",
    "        two = one*2\n",
    "        i.sort()\n",
    "        boundary.append([i[one], i[two]])\n",
    "    return boundary\n",
    "\n",
    "def analyze(sent, boundary):\n",
    "    seq = token.encode(sent, add_special_tokens=True,max_length=MAX_LEN,pad_to_max_length=True)\n",
    "    attention = [float(i>0) for i in seq]\n",
    "    seq = torch.tensor([seq]).to(device)\n",
    "    attention = torch.tensor([attention]).to(device)\n",
    "    result = model(seq, attention)\n",
    "    Max = -9999999\n",
    "    ctr = 0\n",
    "    idx =0\n",
    "    for i in result[0][0].cpu().detach().numpy():\n",
    "        if Max < i:\n",
    "            Max = i\n",
    "            idx = ctr\n",
    "        ctr += 1\n",
    "    print(Emo[idx])\n",
    "    \n",
    "    if result[0][0][idx].cpu().detach().numpy() > boundary[idx][1]:\n",
    "        print(\"level_3\")\n",
    "    elif result[0][0][idx].cpu().detach().numpy() > boundary[idx][0]:\n",
    "        print(\"level_2\")\n",
    "    else: \n",
    "        print(\"level_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Test Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-10T15:44:23.992001Z",
     "iopub.status.busy": "2022-06-10T15:44:23.991656Z",
     "iopub.status.idle": "2022-06-10T15:44:24.031113Z",
     "shell.execute_reply": "2022-06-10T15:44:24.030078Z",
     "shell.execute_reply.started": "2022-06-10T15:44:23.991967Z"
    }
   },
   "outputs": [],
   "source": [
    "Boundary = ComputeBoundary(train_value)\n",
    "test_sentence = \"He is mad \"\n",
    "analyze(test_sentence, train_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation (Microf, Macrof, Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-10T15:31:53.389592Z",
     "iopub.status.busy": "2022-06-10T15:31:53.389262Z",
     "iopub.status.idle": "2022-06-10T15:31:53.408739Z",
     "shell.execute_reply": "2022-06-10T15:31:53.407562Z",
     "shell.execute_reply.started": "2022-06-10T15:31:53.389561Z"
    }
   },
   "outputs": [],
   "source": [
    "def micro_f(predicts, labels, emotions):\n",
    "    #predicts: [predict]\n",
    "    #labels: [correct label]\n",
    "    #emotions: [emotion]\n",
    "    \n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    n = len(predicts)\n",
    "    \n",
    "    for emotion in emotions:\n",
    "        #Count TruePositive, FalsePositive, FalseNegative\n",
    "        tp = 0\n",
    "        fp = 0\n",
    "        fn = 0\n",
    "        for i in range(n):\n",
    "            if predicts[i] == emotion:\n",
    "                if predicts[i] == labels[i]:\n",
    "                    tp += 1\n",
    "                else:\n",
    "                    fp += 1\n",
    "            elif labels[i] == emotion:\n",
    "                fn += 1\n",
    "        TP += tp\n",
    "        FP += fp\n",
    "        FN += fn\n",
    "        \n",
    "    precision = TP / (TP+FP)\n",
    "    recall = TP / (TP+FN)\n",
    "    f1 = 2*precision*recall/(precision+recall)\n",
    "    return (precision, recall, f1)\n",
    "\n",
    "def macro_f(predicts, labels, emotions):\n",
    "    #predicts: [predict]\n",
    "    #labels: [correct label]\n",
    "    #emotions: [emotion]\n",
    "    \n",
    "    precision = 0\n",
    "    recall = 0\n",
    "    n = len(predicts)\n",
    "    \n",
    "    for emotion in emotions:\n",
    "        #Count TruePositive, FalsePositive, FalseNegative\n",
    "        tp = 0\n",
    "        fp = 0\n",
    "        fn = 0\n",
    "        for i in range(n):\n",
    "            if predicts[i] == emotion:\n",
    "                if predicts[i] == labels[i]:\n",
    "                    tp += 1\n",
    "                else:\n",
    "                    fp += 1\n",
    "            elif labels[i] == emotion:\n",
    "                fn += 1\n",
    "        precision += tp/(tp+fp)\n",
    "        recall += tp/(tp+fn)\n",
    "        \n",
    "    precision /= len(emotions)\n",
    "    recall /= len(emotions)\n",
    "    f1 = 2*precision*recall / (precision+recall)\n",
    "    return (precision, recall, f1)\n",
    "\n",
    "def accuracy(predicts, labels):\n",
    "    #predicts: [predict]\n",
    "    #labels: [correct label]\n",
    "    \n",
    "    correct = 0\n",
    "    n = len(predicts)\n",
    "    \n",
    "    for i in range(n):\n",
    "        if predicts[i] ==labels[i]:\n",
    "            correct += 1\n",
    "            \n",
    "    acc = correct / n\n",
    "    \n",
    "    return acc\n",
    "\n",
    "def PrintEvaluation(predicts, labels, emotions):\n",
    "    Microf = micro_f(predicts, labels, emotions)\n",
    "    Macrof = macro_f(predicts, labels, emotions)\n",
    "    Accuracy = accuracy(predicts, labels)\n",
    "    print(\"Microf: \",Microf)\n",
    "    print(\"Macrof: \",Macrof)\n",
    "    print(\"Accuracy: \",Accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Visualization of confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-10T15:31:58.196031Z",
     "iopub.status.busy": "2022-06-10T15:31:58.195700Z",
     "iopub.status.idle": "2022-06-10T15:31:58.209573Z",
     "shell.execute_reply": "2022-06-10T15:31:58.208339Z",
     "shell.execute_reply.started": "2022-06-10T15:31:58.195998Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    import itertools\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output the Final Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-10T15:37:45.448266Z",
     "iopub.status.busy": "2022-06-10T15:37:45.447933Z",
     "iopub.status.idle": "2022-06-10T15:37:51.172856Z",
     "shell.execute_reply": "2022-06-10T15:37:51.170826Z",
     "shell.execute_reply.started": "2022-06-10T15:37:45.448236Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Train:\")\n",
    "PrintEvaluation(train_emotion, train_labels, Emo)\n",
    "\n",
    "print(\"\\nValidation:\")\n",
    "PrintEvaluation(val_emotion, validation_labels, Emo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(train_labels, train_emotion)\n",
    "plot_confusion_matrix(cm, Emo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(df_val.label, val_emotion)\n",
    "plot_confusion_matrix(cm, Emo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-10T15:15:19.173800Z",
     "iopub.status.busy": "2022-06-10T15:15:19.173501Z",
     "iopub.status.idle": "2022-06-10T15:15:20.026083Z",
     "shell.execute_reply": "2022-06-10T15:15:20.023269Z",
     "shell.execute_reply.started": "2022-06-10T15:15:19.173769Z"
    }
   },
   "outputs": [],
   "source": [
    "!python --version\n",
    "print(\"numpy:\",np.__version__)\n",
    "print(\"pandas:\",pd.__version__)\n",
    "print(\"torch:\",torch.__version__)\n",
    "print(\"seaborn:\",sns.__version__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
